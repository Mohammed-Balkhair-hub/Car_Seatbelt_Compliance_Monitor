{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2pi3pvhUEBCh",
        "outputId": "eb9c65d2-2514-4fdc-a617-6ff4efca4e84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /Users/mohammedbalkhair/.cache/kagglehub/datasets/andrewmvd/car-plate-detection/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"andrewmvd/car-plate-detection\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0UyQLy5g1_Wd"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "\n",
        "model = YOLO('yolo11n.pt')\n",
        "\n",
        "root=path+'/images'\n",
        "import glob\n",
        "images_dir=glob.glob(root+'/*.png')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "S5JiF-I-EdHW"
      },
      "outputs": [],
      "source": [
        "def crop_cars(img , model,save_name,Ann_folder,crop_folder):\n",
        "  results = model.predict(source=img, classes=[2], conf=0.4, imgsz=640)\n",
        "  #print(results[0].boxes)\n",
        "  img = cv2.imread(img)\n",
        "  # 3. Visualize and save the result\n",
        "  for r in results:\n",
        "    # Plot the bounding boxes on the image\n",
        "\n",
        "    annotated_image = r.plot()\n",
        "    # Save or show the image\n",
        "    # if folder is not exist creat it\n",
        "    os.makedirs(Ann_folder, exist_ok=True)\n",
        "    cv2.imwrite(f'{Ann_folder}/{save_name}_Annotated.jpg', annotated_image)\n",
        "\n",
        "\n",
        "\n",
        "    # crop the image\n",
        "    for i,box in enumerate(r.boxes):\n",
        "        x1, y1, x2, y2 = box.xyxy[0]\n",
        "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "        # cheack if there is a box\n",
        "\n",
        "        crop = img[y1:y2, x1:x2]\n",
        "        os.makedirs(crop_folder, exist_ok=True)\n",
        "        crop_save_dir=f'{crop_folder}/{save_name}_{i}.jpg'\n",
        "        #print(crop_save_dir)\n",
        "        cv2.imwrite(f'{crop_folder}/{save_name}_{i}.jpg', crop)\n",
        "\n",
        "    #img=Image.open('detected_cars.jpg')\n",
        "    #img.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dHNtpt-R6NRA",
        "outputId": "c9040a53-08f0-40a6-f144-636cf7dfdae6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 /Users/mohammedbalkhair/.cache/kagglehub/datasets/andrewmvd/car-plate-detection/versions/1/images/Cars207.png: 640x544 (no detections), 70.8ms\n",
            "Speed: 2.7ms preprocess, 70.8ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 544)\n",
            "\n",
            "image 1/1 /Users/mohammedbalkhair/.cache/kagglehub/datasets/andrewmvd/car-plate-detection/versions/1/images/Cars213.png: 480x640 (no detections), 46.8ms\n",
            "Speed: 1.1ms preprocess, 46.8ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /Users/mohammedbalkhair/.cache/kagglehub/datasets/andrewmvd/car-plate-detection/versions/1/images/Cars53.png: 480x640 1 car, 39.5ms\n",
            "Speed: 1.0ms preprocess, 39.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /Users/mohammedbalkhair/.cache/kagglehub/datasets/andrewmvd/car-plate-detection/versions/1/images/Cars47.png: 480x640 2 cars, 39.5ms\n",
            "Speed: 1.1ms preprocess, 39.5ms inference, 0.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "\n",
            "image 1/1 /Users/mohammedbalkhair/.cache/kagglehub/datasets/andrewmvd/car-plate-detection/versions/1/images/Cars90.png: 480x640 3 cars, 38.2ms\n",
            "Speed: 0.9ms preprocess, 38.2ms inference, 0.4ms postprocess per image at shape (1, 3, 480, 640)\n"
          ]
        }
      ],
      "source": [
        "for img in images_dir[:5]:\n",
        "  image_name=img.split('/')[-1].split('.')[0]\n",
        "  crop_cars(img , model,image_name,'cars_Annotated','cars_cropes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Fxcd5Y0CMa2D"
      },
      "outputs": [],
      "source": [
        "def crop_plates(img , model,save_name,Ann_folder,crop_folder):\n",
        "  results = model.predict(source=img)\n",
        "  #print(results[0].boxes)\n",
        "  img = cv2.imread(img)\n",
        "  # 3. Visualize and save the result\n",
        "  for r in results:\n",
        "    # Plot the bounding boxes on the image\n",
        "\n",
        "    annotated_image = r.plot()\n",
        "    # Save or show the image\n",
        "    os.makedirs(Ann_folder, exist_ok=True)\n",
        "    cv2.imwrite(f'{Ann_folder}/{save_name}_Annotated.jpg', annotated_image)\n",
        "\n",
        "\n",
        "    # crop the image\n",
        "    for i,box in enumerate(r.boxes):\n",
        "        x1, y1, x2, y2 = box.xyxy[0]\n",
        "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "        # cheack if there is a box\n",
        "        #print(\"####\"*10)\n",
        "        crop = img[y1:y2, x1:x2]\n",
        "        os.makedirs(crop_folder, exist_ok=True)\n",
        "        crop_save_dir=f'{crop_folder}/{save_name}_{i}.jpg'\n",
        "        #print(crop_save_dir)\n",
        "        cv2.imwrite(f'{crop_folder}/{save_name}_{i}.jpg', crop)\n",
        "\n",
        "    #img=Image.open('detected_cars.jpg')\n",
        "    #img.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cT27LZZpM3g6"
      },
      "outputs": [],
      "source": [
        "cars_dir='cars_cropes'\n",
        "\n",
        "images_dir=glob.glob(cars_dir+'/*.jpg')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "HLgE-_u4NXeP"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "model = YOLO(\"license-plate-finetune-v1n.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IlG-KMInP7dS",
        "outputId": "b1be5395-a9d0-4c28-f59b-96f04c195741"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image 1/1 /Users/mohammedbalkhair/bootcamp/Week-4/car_detection/cars_cropes/Cars90_1.jpg: 288x640 2 License_Plates, 31.0ms\n",
            "Speed: 0.8ms preprocess, 31.0ms inference, 0.4ms postprocess per image at shape (1, 3, 288, 640)\n"
          ]
        }
      ],
      "source": [
        "crop_plates(images_dir[0] , model,image_name,'plates_Annotated','plates_cropes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "bBtJv6v8Rc68"
      },
      "outputs": [],
      "source": [
        "# delete plates_Annotated\n",
        "#import shutil\n",
        "#shutil.rmtree('cropes')\n",
        "#shutil.rmtree('Annotated')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44q8P0ZGRczB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "5SW-FoNBNbNF",
        "outputId": "35474adc-5cbc-4e3b-da85-87838bc956e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 /Users/mohammedbalkhair/bootcamp/Week-4/car_detection/cars_cropes/Cars90_1.jpg: 288x640 2 License_Plates, 80.2ms\n",
            "Speed: 3.0ms preprocess, 80.2ms inference, 0.8ms postprocess per image at shape (1, 3, 288, 640)\n",
            "\n",
            "image 1/1 /Users/mohammedbalkhair/bootcamp/Week-4/car_detection/cars_cropes/Cars90_0.jpg: 224x640 1 License_Plate, 22.9ms\n",
            "Speed: 0.5ms preprocess, 22.9ms inference, 0.3ms postprocess per image at shape (1, 3, 224, 640)\n",
            "\n",
            "image 1/1 /Users/mohammedbalkhair/bootcamp/Week-4/car_detection/cars_cropes/Cars90_2.jpg: 512x640 (no detections), 39.4ms\n",
            "Speed: 1.4ms preprocess, 39.4ms inference, 0.2ms postprocess per image at shape (1, 3, 512, 640)\n",
            "\n",
            "image 1/1 /Users/mohammedbalkhair/bootcamp/Week-4/car_detection/cars_cropes/Cars53_0.jpg: 416x640 1 License_Plate, 31.8ms\n",
            "Speed: 1.0ms preprocess, 31.8ms inference, 0.3ms postprocess per image at shape (1, 3, 416, 640)\n",
            "\n",
            "image 1/1 /Users/mohammedbalkhair/bootcamp/Week-4/car_detection/cars_cropes/Cars47_0.jpg: 576x640 1 License_Plate, 46.7ms\n",
            "Speed: 0.9ms preprocess, 46.7ms inference, 0.3ms postprocess per image at shape (1, 3, 576, 640)\n"
          ]
        }
      ],
      "source": [
        "for img in images_dir[:5]:\n",
        "  image_name=img.split('/')[-1].split('.')[0]\n",
        "  crop_plates(img , model,image_name,'plates_Annotated','plates_cropes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qoGJ2SzqX9zw",
        "outputId": "0a3f9203-27e5-49d9-b8d7-1841d58b4953"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'plates_cropes/Cars90_1.jpg'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plates_dir='plates_cropes'\n",
        "\n",
        "plates_dir=glob.glob(plates_dir+'/*.jpg')\n",
        "plates_dir[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "b0WaaCZjZE2t"
      },
      "outputs": [],
      "source": [
        "import easyocr\n",
        "\n",
        "def extract_text(plate_image,save_name):\n",
        "\n",
        "  reader = easyocr.Reader(['en'], gpu=True)\n",
        "\n",
        "  # Pass the image path or URL\n",
        "  image_path = plate_image\n",
        "  results = reader.readtext(image_path)\n",
        "\n",
        "  # Print results\n",
        "  texts=[]\n",
        "  confidence_sum=0\n",
        "  for (bbox, text, confidence) in results:\n",
        "      # Optional: Filter for text that looks like a plate (e.g., alphanumeric)\n",
        "      texts.append(text)\n",
        "      confidence_sum+=confidence\n",
        "\n",
        "      print(f\"Detected Plate: {text} (Confidence: {confidence:.2f})\")\n",
        "  if len(results)!=0:\n",
        "    avg_confidence=confidence_sum/len(results)\n",
        "\n",
        "    return {f\"{save_name}\":{\n",
        "\n",
        "        'text':f\"{','.join(texts)}\",\n",
        "        'avg_confidence':f\"{avg_confidence}\"\n",
        "        }}\n",
        "  else:\n",
        "    return {f\"{save_name}\":{\n",
        "\n",
        "        'text':f\"None\",\n",
        "        'avg_confidence':f\"None\"\n",
        "        }}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZ0m6fx4YNBY",
        "outputId": "e0b80259-1f78-403f-b62e-9328f3ead5d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "plates_cropes/Cars90_0_0.jpg\n",
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'test_plate': {'text': 'None', 'avg_confidence': 'None'}}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(plates_dir[4])\n",
        "extract_text(plates_dir[4],'test_plate')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tscLVXyoeXgZ",
        "outputId": "e33be292-fcc0-4374-a91a-c70f7cfa9dea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cars90_1\n",
            "Cars90_0\n",
            "Cars47_0_0\n",
            "Cars53_0_0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mohammedbalkhair/bootcamp/Week-4/car_detection/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Detected Plate: chio OSE (Confidence: 0.77)\n",
            "Cars90_0_0\n",
            "Cars90_1_1\n",
            "Cars90_1_0\n"
          ]
        }
      ],
      "source": [
        "# define array that will contains dicts\n",
        "results=[]\n",
        "for plate in plates_dir[:10]:\n",
        "  image_name=plate.split('/')[-1].split('.')[0]\n",
        "  print(image_name)\n",
        "  results.append(extract_text(plate,image_name))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ZYouYx2SerEQ"
      },
      "outputs": [],
      "source": [
        "# convert results to json\n",
        "import json\n",
        "with open('results.json', 'w') as fp:\n",
        "    json.dump(results, fp,indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'dataset/test/images/outp0_293_png.rf.76d9748ce7a8bfe9c519a67d3a8d08c0.jpg'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cars_dir='dataset/test/images'\n",
        "\n",
        "cars_dir=glob.glob(cars_dir+'/*.jpg')\n",
        "cars_dir[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# person-noseatbelt (Index 9) -  person-seatbelt (Index 10) - seatbelt (Index 11)\n",
        "def crop_seatbelt(img , model,save_name,Ann_folder,crop_folder):\n",
        "  results = model.predict(source=img,classes=[9, 10, 11],conf=0.55)\n",
        "  #print(results[0].boxes)\n",
        "  img = cv2.imread(img)\n",
        "  # 3. Visualize and save the result\n",
        "  for r in results:\n",
        "    # Plot the bounding boxes on the image\n",
        "\n",
        "    annotated_image = r.plot()\n",
        "    # Save or show the image\n",
        "    os.makedirs(Ann_folder, exist_ok=True)\n",
        "    cv2.imwrite(f'{Ann_folder}/{save_name}_Annotated.jpg', annotated_image)\n",
        "\n",
        "\n",
        "    # crop the image\n",
        "    for i,box in enumerate(r.boxes):\n",
        "        x1, y1, x2, y2 = box.xyxy[0]\n",
        "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
        "        # cheack if there is a box\n",
        "        #print(\"####\"*10)\n",
        "        crop = img[y1:y2, x1:x2]\n",
        "        os.makedirs(crop_folder, exist_ok=True)\n",
        "        crop_save_dir=f'{crop_folder}/{save_name}_{i}.jpg'\n",
        "        #print(crop_save_dir)\n",
        "        cv2.imwrite(f'{crop_folder}/{save_name}_{i}.jpg', crop)\n",
        "\n",
        "    #img=Image.open('detected_cars.jpg')\n",
        "    #img.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# 1. Load your custom-trained weights\n",
        "# Use 'best.pt' for the highest accuracy found during training\n",
        "model = YOLO(\"seat_belt_fast/10_epoch_m3/weights/best.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/1 /Users/mohammedbalkhair/bootcamp/Week-4/car_detection/dataset/test/images/789_png_jpg.rf.a4a06c1a12a185faabb914c3c71b7c94.jpg: 640x640 (no detections), 74.2ms\n",
            "Speed: 4.1ms preprocess, 74.2ms inference, 0.3ms postprocess per image at shape (1, 3, 640, 640)\n"
          ]
        }
      ],
      "source": [
        "crop_seatbelt(cars_dir[40] , model,'test_seatbelt','seatbelt_Annotated','seatbelt_cropes')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
